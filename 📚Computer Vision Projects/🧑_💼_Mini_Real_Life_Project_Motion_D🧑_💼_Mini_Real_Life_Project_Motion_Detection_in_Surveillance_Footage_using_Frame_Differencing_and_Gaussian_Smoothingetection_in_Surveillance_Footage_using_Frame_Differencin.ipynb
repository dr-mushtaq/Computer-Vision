{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üßë‚Äçüíº Mini Real-Life Project: Motion Detection in Surveillance Footage using Frame Differencing and Gaussian Smoothing"
      ],
      "metadata": {
        "id": "WeDnlkHLLihy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úÖ Why this matters**\n",
        "\n",
        "In security cameras, detecting motion accurately is critical. But raw footage often contains noise due to lighting changes, compression artifacts, or hardware limitations.\n",
        "\n",
        "We'll combine:\n",
        "\n",
        "Frame differencing for detecting motion\n",
        "\n",
        "Gaussian filtering to suppress noise\n",
        "\n",
        "Averaging and WMA to clean up unstable pixel shifts\n",
        "\n"
      ],
      "metadata": {
        "id": "xRde6yugLrfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üéØ Project Goal**\n",
        "\n",
        "Detect movement between two consecutive video frames while reducing false positives caused by noise."
      ],
      "metadata": {
        "id": "XresD0gtLz3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "ROI_X, ROI_Y, ROI_W, ROI_H = 100, 100, 300, 300\n",
        "prev_frame = None\n",
        "\n",
        "def get_combined_kernel():\n",
        "    wma_kernel = np.array([[1, 2, 1],\n",
        "                           [2, 4, 2],\n",
        "                           [1, 2, 1]], dtype=np.float32)\n",
        "    wma_kernel /= wma_kernel.sum()\n",
        "    return wma_kernel\n",
        "\n",
        "def process_image_mode(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply ROI\n",
        "    roi = gray[ROI_Y:ROI_Y+ROI_H, ROI_X:ROI_X+ROI_W]\n",
        "\n",
        "    # Apply Gaussian and WMA filters\n",
        "    blurred = cv2.GaussianBlur(roi, (5, 5), 1.5)\n",
        "    kernel = get_combined_kernel()\n",
        "    filtered = cv2.filter2D(blurred, -1, kernel)\n",
        "\n",
        "    # Replace ROI in the original image\n",
        "    output = image.copy()\n",
        "    output[ROI_Y:ROI_Y+ROI_H, ROI_X:ROI_X+ROI_W] = cv2.cvtColor(filtered, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Draw ROI rectangle\n",
        "    cv2.rectangle(output, (ROI_X, ROI_Y), (ROI_X+ROI_W, ROI_Y+ROI_H), (0, 255, 0), 2)\n",
        "    return output\n",
        "\n",
        "# For real-time video capture\n",
        "def process_video_frame():\n",
        "    global prev_frame\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        cap.release()\n",
        "        return None\n",
        "    frame = cv2.resize(frame, (640, 480))\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    roi = gray[ROI_Y:ROI_Y+ROI_H, ROI_X:ROI_X+ROI_W]\n",
        "    blurred = cv2.GaussianBlur(roi, (5, 5), 1.5)\n",
        "    kernel = get_combined_kernel()\n",
        "    filtered = cv2.filter2D(blurred, -1, kernel)\n",
        "\n",
        "    motion_mask = np.zeros_like(roi)\n",
        "    if prev_frame is not None:\n",
        "        diff = cv2.absdiff(prev_frame, filtered)\n",
        "        _, motion_mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
        "    prev_frame = filtered.copy()\n",
        "\n",
        "    color_mask = cv2.cvtColor(motion_mask, cv2.COLOR_GRAY2BGR)\n",
        "    frame[ROI_Y:ROI_Y+ROI_H, ROI_X:ROI_X+ROI_W] = cv2.addWeighted(\n",
        "        frame[ROI_Y:ROI_Y+ROI_H, ROI_X:ROI_X+ROI_W], 0.6, color_mask, 0.4, 0)\n",
        "    cv2.rectangle(frame, (ROI_X, ROI_Y), (ROI_X+ROI_W, ROI_Y+ROI_H), (0, 255, 0), 2)\n",
        "    cap.release()\n",
        "    return frame\n",
        "\n",
        "def interface_choice(choice, image_input):\n",
        "    if choice == \"Upload Image\":\n",
        "        return process_image_mode(image_input)\n",
        "    elif choice == \"Live Camera\":\n",
        "        return process_video_frame()\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üéØ Real-Life Motion Detection App with ROI Filtering\")\n",
        "\n",
        "    mode = gr.Radio([\"Upload Image\", \"Live Camera\"], label=\"Choose Mode\", value=\"Upload Image\")\n",
        "    image_input = gr.Image(type=\"numpy\", label=\"Upload an Image\", visible=True)\n",
        "    output_image = gr.Image(type=\"numpy\", label=\"Processed Output\")\n",
        "\n",
        "    run_button = gr.Button(\"Run Detection\")\n",
        "\n",
        "    def toggle_visibility(mode_choice):\n",
        "        return gr.update(visible=(mode_choice == \"Upload Image\"))\n",
        "\n",
        "    mode.change(fn=toggle_visibility, inputs=mode, outputs=image_input)\n",
        "    run_button.click(fn=interface_choice, inputs=[mode, image_input], outputs=output_image)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Kb2YFQ7HKjKR",
        "outputId": "5f3a30e9-051e-455e-90a0-14d4a6941804"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bafa3b16fa4bd4c6ba.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bafa3b16fa4bd4c6ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tIZuqDYiLgHJ"
      }
    }
  ]
}