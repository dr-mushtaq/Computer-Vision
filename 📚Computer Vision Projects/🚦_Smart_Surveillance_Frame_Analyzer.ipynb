{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**üéØ Key Features:**\n",
        "\n",
        "Detect motion (moving vehicles)\n",
        "\n",
        "Identify lane lines using Hough Transform\n",
        "\n",
        "Highlight ROI (road region)\n",
        "\n",
        "Add Gaussian noise to simulate real-world conditions\n",
        "\n",
        "Overlay detection info with readable text annotations\n",
        "\n",
        "All combined into a single annotated image output"
      ],
      "metadata": {
        "id": "Ft6o4qNEfF7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**üì¶ Requirements**\n",
        "\n",
        "Install these once (if you're using Google Colab):"
      ],
      "metadata": {
        "id": "m_kd2yDjfTeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio opencv-python-headless numpy pillow\n"
      ],
      "metadata": {
        "id": "iCDoOyY9fbI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "def smart_surveillance(frame1, frame2, sigma=15):\n",
        "    try:\n",
        "        # Convert PIL images to OpenCV format\n",
        "        frame1 = np.array(frame1.convert(\"RGB\"))\n",
        "        frame2 = np.array(frame2.convert(\"RGB\"))\n",
        "        img1 = cv2.resize(frame1, (640, 360))\n",
        "        img2 = cv2.resize(frame2, (640, 360))\n",
        "\n",
        "        # Grayscale conversion\n",
        "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Add Gaussian noise to frame1\n",
        "        noise = np.random.normal(0, sigma, gray1.shape).astype(np.uint8)\n",
        "        noisy1 = cv2.add(gray1, noise)\n",
        "\n",
        "        # Frame differencing\n",
        "        diff = cv2.absdiff(noisy1, gray2)\n",
        "        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
        "        dilated = cv2.dilate(thresh, np.ones((5, 5), np.uint8), iterations=2)\n",
        "\n",
        "        # Motion detection via contours\n",
        "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        output = img2.copy()\n",
        "        motion_detected = False\n",
        "        for cnt in contours:\n",
        "            if cv2.contourArea(cnt) > 500:\n",
        "                x, y, w, h = cv2.boundingRect(cnt)\n",
        "                cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(output, \"Motion\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                motion_detected = True\n",
        "\n",
        "        # Lane detection via Hough Transform\n",
        "        edges = cv2.Canny(gray2, 50, 150)\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 80, minLineLength=50, maxLineGap=20)\n",
        "        if lines is not None:\n",
        "            for line in lines[:10]:  # Draw top 10 lines\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                cv2.line(output, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            cv2.putText(output, \"Lanes Detected\", (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "        if not motion_detected:\n",
        "            cv2.putText(output, \"No Motion Detected\", (10, 60),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        # Draw ROI\n",
        "        cv2.rectangle(output, (100, 250), (540, 330), (0, 255, 255), 2)\n",
        "        cv2.putText(output, \"ROI\", (100, 245), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
        "\n",
        "        return output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Processing error:\", str(e))\n",
        "        error_img = np.zeros((360, 640, 3), dtype=np.uint8)\n",
        "        cv2.putText(error_img, \"‚ùå Error during processing\", (50, 180),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
        "        return error_img\n",
        "\n",
        "# Gradio Web Interface\n",
        "gr.Interface(\n",
        "    fn=smart_surveillance,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Upload Frame 1\"),\n",
        "        gr.Image(type=\"pil\", label=\"Upload Frame 2\"),\n",
        "        gr.Slider(0, 50, value=15, label=\"Gaussian Noise Sigma\")\n",
        "    ],\n",
        "    outputs=gr.Image(label=\"üß† Processed Surveillance Frame\"),\n",
        "    title=\"üöó Motion & Lane Detection Tool\",\n",
        "    description=\"Detect motion and road lanes from two street view frames. Simulates noise and draws region of interest (ROI).\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "id": "-kD2myLJeend"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nYvAShgZfH-M"
      }
    }
  ]
}